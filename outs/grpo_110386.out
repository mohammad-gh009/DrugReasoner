🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.
Unsloth: Failed to patch Gemma3ForConditionalGeneration.
🦥 Unsloth Zoo will now patch everything to make training faster!
INFO 04-10 18:05:01 [__init__.py:239] Automatically detected platform cuda.
==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.1. vLLM: 0.8.3.
   \\   /|    Tesla V100-PCIE-32GB. Num GPUs = 1. Max memory: 31.739 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 7.0. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: Your GPU does not support prefix caching - will disable!
Unsloth: vLLM loading /home/u111169/wrkdir/mgh-project/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659 with actual GPU utilization = 59.35%
Unsloth: Your GPU has CUDA compute capability 7.0 with VRAM = 31.74 GB.
Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 5000. Num Sequences = 160.
Unsloth: vLLM's KV Cache can use up to 3.84 GB. Also swap space = 6 GB.
WARNING 04-10 18:05:04 [config.py:2704] Casting torch.bfloat16 to torch.float16.
INFO 04-10 18:05:13 [config.py:600] This model supports multiple tasks: {'reward', 'classify', 'embed', 'score', 'generate'}. Defaulting to 'generate'.
WARNING 04-10 18:05:13 [arg_utils.py:1708] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. 
Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'fp4', 'bnb_4bit_use_double_quant': False, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': [], 'llm_int8_threshold': 6.0}
INFO 04-10 18:05:13 [llm_engine.py:242] Initializing a V0 LLM engine (v0.8.3) with config: model='/home/u111169/wrkdir/mgh-project/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659', speculative_config=None, tokenizer='/home/u111169/wrkdir/mgh-project/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=5000, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/u111169/wrkdir/mgh-project/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":0,"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":160}, use_cached_outputs=False, 
/share/apps/eb/Python/3.11.5-GCCcore-13.2.0/envs/vllm/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py:29: UserWarning: Failed to get the IP address, using 0.0.0.0 by default.The value can be set by the environment variable VLLM_HOST_IP or HOST_IP.
  get_ip(), get_open_port())
INFO 04-10 18:05:14 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.
INFO 04-10 18:05:14 [cuda.py:289] Using XFormers backend.
[W410 18:05:14.369453232 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3
[W410 18:05:14.369727025 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3
INFO 04-10 18:05:14 [parallel_state.py:957] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 04-10 18:05:14 [model_runner.py:1110] Starting to load model /home/u111169/wrkdir/mgh-project/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659...
INFO 04-10 18:05:14 [loader.py:1155] Loading weights with BitsAndBytes quantization. May take a while ...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:19<00:59, 19.75s/it]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [01:49<02:01, 60.68s/it]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [03:10<01:10, 70.23s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [04:30<00:00, 73.88s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [04:30<00:00, 67.54s/it]

INFO 04-10 18:09:45 [punica_selector.py:18] Using PunicaWrapperGPU.
INFO 04-10 18:09:45 [model_runner.py:1146] Model loading took 5.4012 GiB and 270.408638 seconds
INFO 04-10 18:10:00 [worker.py:267] Memory profiling takes 15.13 seconds
INFO 04-10 18:10:00 [worker.py:267] the current vLLM instance can use total_gpu_memory (31.74GiB) x gpu_memory_utilization (0.59) = 18.84GiB
INFO 04-10 18:10:00 [worker.py:267] model weights take 5.40GiB; non_torch_memory takes 0.07GiB; PyTorch activation peak memory takes 0.77GiB; the rest of the memory reserved for KV Cache is 12.59GiB.
INFO 04-10 18:10:01 [executor_base.py:112] # cuda blocks: 6448, # CPU blocks: 3072
INFO 04-10 18:10:01 [executor_base.py:117] Maximum concurrency for 5000 tokens per request: 20.63x
INFO 04-10 18:10:03 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/23 [00:00<?, ?it/s]Capturing CUDA graph shapes:   4%|▍         | 1/23 [00:04<01:39,  4.51s/it]Capturing CUDA graph shapes:   9%|▊         | 2/23 [00:05<00:57,  2.73s/it]Capturing CUDA graph shapes:  13%|█▎        | 3/23 [00:07<00:43,  2.16s/it]Capturing CUDA graph shapes:  17%|█▋        | 4/23 [00:08<00:35,  1.89s/it]Capturing CUDA graph shapes:  22%|██▏       | 5/23 [00:10<00:30,  1.69s/it]Capturing CUDA graph shapes:  26%|██▌       | 6/23 [00:14<00:42,  2.51s/it]Capturing CUDA graph shapes:  30%|███       | 7/23 [00:18<00:48,  3.04s/it]Capturing CUDA graph shapes:  35%|███▍      | 8/23 [00:19<00:37,  2.49s/it]Capturing CUDA graph shapes:  39%|███▉      | 9/23 [00:21<00:29,  2.13s/it]Capturing CUDA graph shapes:  43%|████▎     | 10/23 [00:22<00:24,  1.88s/it]Capturing CUDA graph shapes:  48%|████▊     | 11/23 [00:23<00:20,  1.71s/it]Capturing CUDA graph shapes:  52%|█████▏    | 12/23 [00:25<00:17,  1.60s/it]Capturing CUDA graph shapes:  57%|█████▋    | 13/23 [00:26<00:14,  1.47s/it]Capturing CUDA graph shapes:  61%|██████    | 14/23 [00:27<00:12,  1.38s/it]Capturing CUDA graph shapes:  65%|██████▌   | 15/23 [00:28<00:10,  1.31s/it]Capturing CUDA graph shapes:  70%|██████▉   | 16/23 [00:29<00:08,  1.27s/it]Capturing CUDA graph shapes:  74%|███████▍  | 17/23 [00:31<00:07,  1.25s/it]Capturing CUDA graph shapes:  78%|███████▊  | 18/23 [00:32<00:06,  1.24s/it]Capturing CUDA graph shapes:  83%|████████▎ | 19/23 [00:33<00:05,  1.31s/it]Capturing CUDA graph shapes:  87%|████████▋ | 20/23 [00:34<00:03,  1.26s/it]Capturing CUDA graph shapes:  91%|█████████▏| 21/23 [00:35<00:02,  1.22s/it]Capturing CUDA graph shapes:  96%|█████████▌| 22/23 [00:37<00:01,  1.19s/it]Capturing CUDA graph shapes: 100%|██████████| 23/23 [00:43<00:00,  2.67s/it]Capturing CUDA graph shapes: 100%|██████████| 23/23 [00:43<00:00,  1.88s/it]
INFO 04-10 18:10:46 [model_runner.py:1598] Graph capturing finished in 43 secs, took 3.07 GiB
INFO 04-10 18:10:46 [llm_engine.py:448] init engine (profile, create kv cache, warmup model) took 61.55 seconds
/home/u111169/wrkdir/mgh-project/models/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659 does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.
Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
Map:   0%|          | 0/2497 [00:00<?, ? examples/s]Map:  61%|██████    | 1528/2497 [00:00<00:00, 15165.68 examples/s]Map: 100%|██████████| 2497/2497 [00:00<00:00, 14145.33 examples/s]
Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.
We will change the batch size of 1 to the `num_generations` of 4
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/u111169/mgh/grpo.py", line 142, in <module>
[rank0]:     training_args = GRPOConfig(
[rank0]:                     ^^^^^^^^^^^
[rank0]:   File "/home/u111169/mgh/unsloth_compiled_cache/UnslothGRPOTrainer.py", line 526, in __init__
[rank0]:     super().__init__(
[rank0]: TypeError: GRPOConfig.__init__() got an unexpected keyword argument 'mask_truncated_completions'
[rank0]:[W410 18:10:54.206795443 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
#################################################
Panthera Cluster
Job 110386 for user 'u111169'
Finished at: Thu Apr 10 18:10:57 +0330 2025
Job details file : ~/JobSummary/110386.out
================================================
